% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{liDeepFacialExpression2020}
S.~Li and W.~Deng, ``Deep facial expression recognition: {{A}} survey,''
  \emph{IEEE transactions on affective computing}, 2020, review on Machine
  Learning Models.

\bibitem{melloukFacialEmotionRecognition2020}
W.~Mellouk and W.~Handouzi, ``Facial emotion recognition using deep learning:
  Review and insights,'' \emph{Procedia Computer Science}, vol. 175, pp.
  689--694, 2020, review on Machine Learning Models.

\bibitem{AffectivaHumanizingTechnology2021}
``Affectiva - {{Humanizing Technology}},'' https://www.affectiva.com/, Nov.
  2021.

\bibitem{Replika2021}
``Replika,'' https://replika.com, Nov. 2021.

\bibitem{davenportHowArtificialIntelligence2020}
T.~Davenport, A.~Guha, D.~Grewal, and T.~Bressgott, ``How artificial
  intelligence will change the future of marketing,'' \emph{Journal of the
  Academy of Marketing Science}, vol.~48, no.~1, pp. 24--42, 2020.

\bibitem{davoliDriverBehaviorRecognition2020}
L.~Davoli, M.~Martalo, A.~Cilfone, L.~Belli, G.~Ferrari, R.~Presta,
  R.~Montanari, M.~Mengoni, L.~Giraldi, E.~G. Amparore, M.~Botta, I.~Drago,
  G.~Carbonara, A.~Castellano, and J.~Plomp, ``On {{Driver Behavior
  Recognition}} for {{Increased Safety}}: {{A Roadmap}},'' \emph{Safety},
  vol.~6, no.~4, Dec. 2020.

\bibitem{huangArtificialIntelligenceService2018}
M.-H. Huang and R.~T. Rust, ``Artificial intelligence in service,''
  \emph{Journal of Service Research}, vol.~21, no.~2, pp. 155--172, 2018.

\bibitem{kristenfrenchYourNewBest2018}
K.~French, ``Your new best friend: {{AI}} chatbot,'' 2018, the following values
  have no corresponding Zotero field:\\ number: 31.05.2021.

\bibitem{huangStrategicFrameworkArtificial2021}
M.-H. Huang and R.~T. Rust, ``A strategic framework for artificial intelligence
  in marketing,'' \emph{Journal of the Academy of Marketing Science}, vol.~49,
  no.~1, pp. 30--50, Jan. 2021, the following values have no corresponding
  Zotero field:\\ accession-num: WOS:000585729700001.

\bibitem{marin-moralesAffectiveComputingVirtual2018}
J.~{Mar{\'i}n-Morales}, J.~L. {Higuera-Trujillo}, A.~Greco, J.~Guixeres,
  C.~Llinares, E.~P. Scilingo, M.~Alca{\~n}iz, and G.~Valenza, ``Affective
  computing in virtual reality: Emotion recognition from brain and heartbeat
  dynamics using wearable sensors,'' \emph{Scientific reports}, vol.~8, no.~1,
  pp. 1--15, 2018.

\bibitem{ekmanBasicEmotionsHandbook1999}
P.~Ekman, ``Basic emotions. {{Handbook}} of cognition and emotion,''
  \emph{Wiley, New York}, pp. 301--320, 1999.

\bibitem{johnsonAdvancingNeuroscienceWearable2020}
K.~T. Johnson and R.~W. Picard, ``Advancing {{Neuroscience}} through {{Wearable
  Devices}},'' \emph{Neuron}, vol. 108, no.~1, pp. 8--12, 2020.

\bibitem{shoumyMultimodalBigData2020}
N.~J. Shoumy, L.-M. Ang, K.~P. Seng, D.~M. Rahaman, and T.~Zia, ``Multimodal
  big data affective analytics: {{A}} comprehensive survey using text, audio,
  visual and physiological signals,'' \emph{Journal of Network and Computer
  Applications}, vol. 149, p. 102447, 2020.

\bibitem{generosiDeepLearningbasedSystem2018}
A.~Generosi, S.~Ceccacci, and M.~Mengoni, ``A deep learning-based system to
  track and analyze customer behavior in retail store,'' in \emph{2018 {{IEEE}}
  8th {{International Conference}} on {{Consumer Electronics-Berlin}}
  ({{ICCE-Berlin}})}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2018, pp.
  1--6.

\bibitem{shaoThreeConvolutionalNeural2019}
J.~Shao and Y.~Qian, ``Three convolutional neural network models for facial
  expression recognition in the wild,'' \emph{Neurocomputing}, vol. 355, pp.
  82--92, 2019.

\bibitem{darwinExpressionEmotionsMan1872}
C.~Darwin, \emph{The Expression of the Emotions in Man and Animals}.\hskip 1em
  plus 0.5em minus 0.4em\relax {John Murray}, 1872.

\bibitem{tianRecognizingActionUnits2001}
Y.-I. Tian, T.~Kanade, and J.~F. Cohn, ``Recognizing action units for facial
  expression analysis,'' \emph{IEEE Transactions on pattern analysis and
  machine intelligence}, vol.~23, no.~2, pp. 97--115, 2001.

\bibitem{rouastDeepLearningHuman2019}
P.~V. Rouast, M.~Adam, and R.~Chiong, ``Deep learning for human affect
  recognition: {{Insights}} and new developments,'' \emph{IEEE Transactions on
  Affective Computing}, 2019, review on Machine Learning Models.

\bibitem{ekundayoFacialExpressionRecognition2021}
O.~S. Ekundayo and S.~Viriri, ``Facial {{Expression Recognition}}: {{A Review}}
  of {{Trends}} and {{Techniques}},'' \emph{Ieee Access}, vol.~9, pp.
  136\,944--136\,973, 2021, overview of FER databases on p. 9 \par Summary of
  popular Deep CNN \par Summary of experimental results for different models
  and datasets.

\bibitem{gebeleFaceValueImpact2022}
J.~Gebele, P.~Brune, and S.~Fau√üer, ``Face {{Value}}: {{On}} the {{Impact}} of
  {{Annotation}} ({{In-}}){{Consistencies}} and {{Label Ambiguity}} in {{Facial
  Data}} on {{Emotion Recognition}},'' in \emph{2022 26th {{International
  Conference}} on {{Pattern Recognition}} ({{ICPR}})}, pp. 2597--2604.

\bibitem{ekmanConstantsCulturesFace1971}
P.~Ekman and W.~V. Friesen, ``Constants across cultures in the face and
  emotion.'' \emph{Journal of personality and social psychology}, vol.~17,
  no.~2, p. 124, 1971, emotion Theory Concepts, for instance ekman and
  pleasure-arousal-dominance framework (PAD) or newer concepts like Plutchnik
  model.

\bibitem{ekweaririFacialExpressionRecognition2017}
A.~N. Ekweariri and K.~Yurtkan, ``Facial expression recognition using enhanced
  local binary patterns,'' in \emph{2017 9th International Conference on
  {{Computational Intelligence}} and {{Communication Networks}}
  ({{CICN}})}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2017, pp. 43--47.

\bibitem{jaisonReviewFacialEmotion2021}
A.~Jaison and C.~Deepa, ``A {{Review}} on {{Facial Emotion Recognition}} and
  {{Classification Analysis}} with {{Deep Learning}},'' \emph{Bioscience
  Biotechnology Research Communications}, vol.~14, no.~5, pp. 154--161, 2021,
  methodological Approach NOT to complex.

\bibitem{khaireddinFacialEmotionRecognition2021}
Y.~Khaireddin and Z.~Chen, ``Facial {{Emotion Recognition}}: {{State}} of the
  {{Art Performance}} on {{FER2013}},'' \emph{arXiv:2105.03588 [cs]}, May 2021,
  comment: 9 pages, 5 figures, 2 tables.

\bibitem{quinnRealtimeEmotionRecognition2017}
M.-A. Quinn, G.~Sivesind, and G.~Reis, ``Real-time emotion recognition from
  facial expressions,'' \emph{Standford University}, 2017.

\bibitem{liuAdaptiveDeepMetric2017}
X.~Liu, B.~V. K.~V. Kumar, J.~You, and P.~Jia, ``Adaptive {{Deep Metric
  Learning}} for {{Identity-Aware Facial Expression Recognition}},'' in
  \emph{2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern
  Recognition Workshops}} ({{CVPRW}})}, Jul. 2017, pp. 522--531.

\bibitem{yangFacialExpressionRecognition2018}
H.~Yang, U.~Ciftci, and L.~Yin, ``Facial {{Expression Recognition}} by
  {{De-expression Residue Learning}},'' in \emph{2018 {{IEEE}}/{{CVF
  Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, Jun. 2018,
  pp. 2168--2177.

\bibitem{lecunGradientbasedLearningApplied1998}
Y.~Lecun, L.~Bottou, Y.~Bengio, and P.~Haffner, ``Gradient-based learning
  applied to document recognition,'' \emph{Proceedings of the IEEE}, vol.~86,
  no.~11, pp. 2278--2324, Nov. 1998.

\bibitem{krizhevskyImagenetClassificationDeep2012}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' \emph{Advances in neural information
  processing systems}, vol.~25, pp. 1097--1105, 2012.

\bibitem{szegedyGoingDeeperConvolutions2015a}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich, ``Going deeper with convolutions,'' in
  \emph{Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern
  Recognition}, 2015, pp. 1--9.

\bibitem{simonyanVeryDeepConvolutional2015}
K.~Simonyan and A.~Zisserman, ``Very {{Deep Convolutional Networks}} for
  {{Large-Scale Image Recognition}},'' \emph{arXiv:1409.1556 [cs]}, Apr. 2015.

\bibitem{heDeepResidualLearning2016}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep {{Residual Learning}} for {{Image
  Recognition}},'' in \emph{2016 {{IEEE Conference}} on {{Computer Vision}} and
  {{Pattern Recognition}} ({{CVPR}})}, Jun. 2016, pp. 770--778.

\bibitem{cholletXceptionDeepLearning2017}
F.~Chollet, ``Xception: {{Deep}} learning with depthwise separable
  convolutions,'' in \emph{Proceedings of the {{IEEE}} Conference on Computer
  Vision and Pattern Recognition}, 2017, pp. 1251--1258.

\bibitem{huSqueezeandExcitationNetworks2018}
J.~Hu, L.~Shen, and G.~Sun, ``Squeeze-and-{{Excitation Networks}},'' in
  \emph{2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern
  Recognition}}}, Jun. 2018, pp. 7132--7141.

\bibitem{p.luceyExtendedCohnKanadeDataset2010}
P.~Lucey, J.~F. Cohn, T.~Kanade, J.~Saragih, Z.~Ambadar, and I.~Matthews, ``The
  {{Extended Cohn-Kanade Dataset}} ({{CK}}+): {{A}} complete dataset for action
  unit and emotion-specified expression,'' in \emph{2010 {{IEEE Computer
  Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} -
  {{Workshops}}}, Jun. 2010, pp. 94--101, the following values have no
  corresponding Zotero field:\\ alt-title: 2010 IEEE Computer Society
  Conference on Computer Vision and Pattern Recognition - Workshops.

\bibitem{lyonsCodingFacialExpressions1998}
M.~Lyons, S.~Akamatsu, M.~Kamachi, and J.~Gyoba, ``Coding facial expressions
  with {{Gabor}} wavelets,'' in \emph{Proceedings {{Third IEEE International
  Conference}} on {{Automatic Face}} and {{Gesture Recognition}}}, Apr. 1998,
  pp. 200--205.

\bibitem{mollahosseiniAffectnetDatabaseFacial2017}
A.~Mollahosseini, B.~Hasani, and M.~H. Mahoor, ``Affectnet: {{A}} database for
  facial expression, valence, and arousal computing in the wild,'' \emph{IEEE
  Transactions on Affective Computing}, vol.~10, no.~1, pp. 18--31, 2017.

\bibitem{liReliableCrowdsourcingDeep2017}
S.~Li, W.~Deng, and J.~Du, ``Reliable {{Crowdsourcing}} and {{Deep
  Locality-Preserving Learning}} for {{Expression Recognition}} in the
  {{Wild}},'' in \emph{2017 {{IEEE Conference}} on {{Computer Vision}} and
  {{Pattern Recognition}} ({{CVPR}})}.\hskip 1em plus 0.5em minus 0.4em\relax
  {Honolulu, HI}: {IEEE}, Jul. 2017, pp. 2584--2593.

\bibitem{ekmanUnmaskingFaceGuide2003}
P.~Ekman and W.~V. Friesen, \emph{Unmasking the Face: {{A}} Guide to
  Recognizing Emotions from Facial Clues}.\hskip 1em plus 0.5em minus
  0.4em\relax {Ishk}, 2003, vol.~10.

\bibitem{goodfellowChallengesRepresentationLearning2013}
I.~J. Goodfellow, D.~Erhan, P.~L. Carrier, A.~Courville, M.~Mirza, B.~Hamner,
  W.~Cukierski, Y.~Tang, D.~Thaler, D.-H. Lee, Y.~Zhou, C.~Ramaiah, F.~Feng,
  R.~Li, X.~Wang, D.~Athanasakis, J.~{Shawe-Taylor}, M.~Milakov, J.~Park,
  R.~Ionescu, M.~Popescu, C.~Grozea, J.~Bergstra, J.~Xie, L.~Romaszko, B.~Xu,
  Z.~Chuang, and Y.~Bengio, ``Challenges in {{Representation Learning}}: {{A}}
  report on three machine learning contests,'' \emph{arXiv:1307.0414 [cs,
  stat]}, Jul. 2013, comment: 8 pages, 2 figures.

\bibitem{NVIDIADataScience2021}
``{{NVIDIA Data Science Stack}},'' NVIDIA Corporation, Dec. 2021.

\bibitem{knyazevConvolutionalNeuralNetworks2017}
B.~Knyazev, R.~Shvetsov, N.~Efremova, and A.~Kuharenko, ``Convolutional neural
  networks pretrained on large face recognition datasets for emotion
  classification from video,'' \emph{arXiv:1711.04598 [cs]}, Nov. 2017,
  comment: 4 pages.

\end{thebibliography}
